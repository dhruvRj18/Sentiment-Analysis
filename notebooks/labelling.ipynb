{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "728b89f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\nihal\\AppData\\Roaming\\nltk_data...\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "input_file_path = \"../data/text_based_posts.txt\"\n",
    "\n",
    "with open(input_file_path, \"r\", encoding=\"utf-8\") as input_file:\n",
    "    examples = input_file.read().split(\"Text Content:\")\n",
    "\n",
    "annotated_dataset = []\n",
    "\n",
    "for example in examples:\n",
    "    if not example.strip():\n",
    "        continue\n",
    "    \n",
    "    text_content = example.strip()\n",
    "    \n",
    "    sentiment_scores = sia.polarity_scores(text_content)\n",
    "    \n",
    "    if sentiment_scores['compound'] >= 0.05:\n",
    "        sentiment_label = 'positive'\n",
    "    elif sentiment_scores['compound'] <= -0.05:\n",
    "        sentiment_label = 'negative'\n",
    "    else:\n",
    "        sentiment_label = 'neutral'\n",
    "    \n",
    "    annotated_dataset.append({\n",
    "        'text_content': text_content,\n",
    "        'sentiment': sentiment_label,\n",
    "        'sentiment_score': sentiment_scores['compound']\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eac9e8bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9380"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(annotated_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcc05256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9381"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb90f6ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text_content': 'Hi! I did a family session last week using a wrinkled backdrop, the intent being to mask/smooth/remove and replace with a clean white background. I can do this slowly by hand in photoshop, but I know this stuff has evolved leaps and bounds in the past couple of years. Any recommendations for the easiest-to-use sites or software to cruise through 40-50 photos? I have an adobe sub but nothing else; tried some of those \"free\" online sites (canva, etc) but every one requires a subscription purchase to download high-res images. I get it, but this is also a one-off for me, almost never need this kind of editing these days, so hoping for more of a one-time solution!\\n\\n&#x200B;\\n\\nthanks!',\n",
       " 'sentiment': 'positive',\n",
       " 'sentiment_score': 0.9513}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotated_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d9c308b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Neutral Sentiment Tags: 420\n",
      "Length of Positive Sentiment Tags: 7460\n",
      "Length of Negative Sentiment Tags: 1500\n"
     ]
    }
   ],
   "source": [
    "neutral_count = 0\n",
    "pos_count = 0\n",
    "neg_count = 0\n",
    "for entry in annotated_dataset:\n",
    "    if entry['sentiment'] == 'neutral':\n",
    "        neutral_count += 1\n",
    "    if entry['sentiment'] == 'negative':\n",
    "        neg_count += 1\n",
    "    if entry['sentiment'] == 'positive':\n",
    "        pos_count += 1\n",
    "    \n",
    "print(\"Length of Neutral Sentiment Tags:\", neutral_count)\n",
    "print(\"Length of Positive Sentiment Tags:\", pos_count)\n",
    "print(\"Length of Negative Sentiment Tags:\", neg_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29a4a593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotated dataset saved to ../data/labelled_data.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "output_json_path = \"../data/labelled_data.json\"\n",
    "\n",
    "with open(output_json_path, 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(annotated_dataset, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"Annotated dataset saved to {output_json_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692ad650",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
