{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "d8e98aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manipulation data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#visualiation data\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import matplotlib\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "\n",
    "\n",
    "#from dataprep.eda import *\n",
    "#from dataprep.datasets import load_dataset\n",
    "#from dataprep.eda import create_report\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import r2_score, classification_report\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "import math\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "\n",
    "\n",
    "import datetime as dt\n",
    "import requests\n",
    "import json\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "# Import snscrape\n",
    "import snscrape.modules.twitter as sntwitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "c927000b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "770d261a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "reddit = praw.Reddit(client_id ='6d70d19AQb3YLMNkHzXyow',\n",
    "client_secret ='74mCP3YG8SveaELNtR3mdSXxspuWkQ',\n",
    "user_agent ='sentiment analysis')\n",
    "\n",
    "print(reddit.read_only)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "0668c114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of posts to fetch in each request\n",
    "batch_size = 30000\n",
    "num_batches = 10  # You can adjust this based on your needs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "02cd607d",
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddit = reddit.subreddit('politics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "965f3734",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_path = \"../data/text_based_posts.txt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "4af9e877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching batch 1/10\n",
      "Fetching batch 2/10\n",
      "Fetching batch 3/10\n",
      "Fetching batch 4/10\n",
      "Fetching batch 5/10\n",
      "Fetching batch 6/10\n",
      "Fetching batch 7/10\n",
      "Fetching batch 8/10\n",
      "Fetching batch 9/10\n",
      "Fetching batch 10/10\n"
     ]
    }
   ],
   "source": [
    "# Print or process the posts as needed\n",
    "with open(output_file_path, \"w\", encoding=\"utf-8\") as output_file:\n",
    "     for batch_num in range(num_batches):\n",
    "            print(f\"Fetching batch {batch_num + 1}/{num_batches}\")\n",
    "\n",
    "            # Retry mechanism\n",
    "            retry_attempts = 3\n",
    "            for attempt in range(retry_attempts):\n",
    "                try:\n",
    "                    # Fetch posts\n",
    "                    posts = subreddit.new(limit=batch_size)\n",
    "\n",
    "                    # Print or process the text-based posts as needed\n",
    "                    for post in posts:\n",
    "                        # Check if the post has text content\n",
    "                        if post.selftext:\n",
    "                            output_file.write(f\"Text Content: {post.selftext}\\n\")\n",
    "\n",
    "                    # Break the retry loop if successful\n",
    "                    break\n",
    "                except Exception as e:\n",
    "                    print(f\"Error: {e}\")\n",
    "                    print(f\"Retrying ({attempt + 1}/{retry_attempts})...\")\n",
    "                    time.sleep(2 ** attempt)  # Exponential backoff\n",
    "\n",
    "            # Add a delay to avoid rate limiting\n",
    "            time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8b7ffb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
